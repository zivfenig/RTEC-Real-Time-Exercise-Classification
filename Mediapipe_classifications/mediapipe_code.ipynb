{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-13T09:01:04.031313Z",
     "start_time": "2025-04-13T09:01:02.083680Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pickle\n",
    "from collections import deque\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T09:01:04.831812Z",
     "start_time": "2025-04-13T09:01:04.034833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('trainset.pkl', 'rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "\n",
    "# Create and fit the StandardScaler using the training features.\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Load the trained model.\n",
    "with open('model_red_rf.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Label mapping (ensure this matches your model's encoding)\n",
    "label_map = {0: \"Push Ups\", 1: \"Pull Ups\", 2: \"Squats\", 3: \"Jumping Jacks\", 4: \"Planks\"}"
   ],
   "id": "1b2237ed9f920d13",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T09:01:05.020888Z",
     "start_time": "2025-04-13T09:01:05.002194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the angle calculation function.\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"Calculate the angle (in degrees) at point b given three points.\"\"\"\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n"
   ],
   "id": "1b17cfa7219f531d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T09:01:05.072330Z",
     "start_time": "2025-04-13T09:01:05.057459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_point(landmark, w, h):\n",
    "    \"\"\"Convert normalized landmark to pixel coordinates.\"\"\"\n",
    "    return [int(landmark.x * w), int(landmark.y * h)]"
   ],
   "id": "3bdf33d1006ec5d1",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T09:03:01.465966Z",
     "start_time": "2025-04-13T09:01:05.148823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# ---------------------\n",
    "# Timing Parameters:\n",
    "# measurement_duration: time window for angle data collection (20 sec).\n",
    "# display_duration: time to display the prediction result after measurement (7 sec).\n",
    "measurement_duration = 20  # seconds\n",
    "display_duration = 7       # seconds\n",
    "\n",
    "phase = \"measurement\"   # current phase: either \"measurement\" or \"display\"\n",
    "phase_start_time = time.time()  # starting time for current phase\n",
    "\n",
    "# Storage for accumulated angle data.\n",
    "angle_data = {\n",
    "    'shoulder': [],\n",
    "    'elbow': [],\n",
    "    'hip': [],\n",
    "    'knee': [],\n",
    "    'ankle': []\n",
    "}\n",
    "predicted_label = None  # variable to store prediction from measurement phase\n",
    "\n",
    "# ---------------------\n",
    "# Open the webcam and set up a resizable window.\n",
    "# ---------------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow('MediaPipe Pose', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('MediaPipe Pose', 1280, 720)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,\n",
    "                  min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Unable to read from webcam. Exiting...\")\n",
    "            break\n",
    "\n",
    "        h, w, _ = frame.shape\n",
    "        # Convert the frame from BGR to RGB.\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Process the image.\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert back to BGR.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw pose landmarks.\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Extract left-side landmark points.\n",
    "            left_shoulder = get_point(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value], w, h)\n",
    "            left_elbow = get_point(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value], w, h)\n",
    "            left_wrist = get_point(landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value], w, h)\n",
    "            left_hip = get_point(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value], w, h)\n",
    "            left_knee = get_point(landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value], w, h)\n",
    "            left_ankle = get_point(landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value], w, h)\n",
    "            left_foot = get_point(landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value], w, h)\n",
    "            \n",
    "            # Calculate the five joint angles.\n",
    "            shoulder_angle = calculate_angle(left_elbow, left_shoulder, left_hip)\n",
    "            elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            hip_angle = calculate_angle(left_shoulder, left_hip, left_knee)\n",
    "            knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "            ankle_angle = calculate_angle(left_knee, left_ankle, left_foot)\n",
    "            \n",
    "            # Draw instantaneous angle text (for debugging, optional)\n",
    "            inst_angle_text = (f\"S:{int(shoulder_angle)} E:{int(elbow_angle)} \"\n",
    "                               f\"H:{int(hip_angle)} K:{int(knee_angle)} A:{int(ankle_angle)}\")\n",
    "            cv2.putText(image, inst_angle_text, (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Phase: Measurement\n",
    "            if phase == \"measurement\":\n",
    "                # Accumulate angles.\n",
    "                angle_data['shoulder'].append(shoulder_angle)\n",
    "                angle_data['elbow'].append(elbow_angle)\n",
    "                angle_data['hip'].append(hip_angle)\n",
    "                angle_data['knee'].append(knee_angle)\n",
    "                angle_data['ankle'].append(ankle_angle)\n",
    "            \n",
    "            # Otherwise, if phase == \"display\", nothing new is accumulated.\n",
    "        \n",
    "        # Check phase timing.\n",
    "        elapsed = time.time() - phase_start_time\n",
    "        \n",
    "        if phase == \"measurement\" and elapsed >= measurement_duration:\n",
    "            # Time's up for measurement phase.\n",
    "            avg_shoulder = np.mean(angle_data['shoulder']) if angle_data['shoulder'] else 0\n",
    "            avg_elbow = np.mean(angle_data['elbow']) if angle_data['elbow'] else 0\n",
    "            avg_hip = np.mean(angle_data['hip']) if angle_data['hip'] else 0\n",
    "            avg_knee = np.mean(angle_data['knee']) if angle_data['knee'] else 0\n",
    "            avg_ankle = np.mean(angle_data['ankle']) if angle_data['ankle'] else 0\n",
    "\n",
    "            feature_vector = np.array([avg_shoulder, avg_elbow, avg_hip, avg_knee, avg_ankle]).reshape(1, -1)\n",
    "            feature_vector_scaled = scaler.transform(feature_vector)\n",
    "            # Predict using the model.\n",
    "            pred = model.predict(feature_vector_scaled)[0]\n",
    "            predicted_label = label_map.get(pred, \"Unknown\")\n",
    "            \n",
    "            # Display average angles (for debugging) and prediction on the image.\n",
    "            avg_text = (f\"Avg Angles (20s): S:{int(avg_shoulder)} E:{int(avg_elbow)} \"\n",
    "                        f\"H:{int(avg_hip)} K:{int(avg_knee)} A:{int(avg_ankle)}\")\n",
    "            cv2.putText(image, avg_text, (10, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Switch to display phase.\n",
    "            phase = \"display\"\n",
    "            phase_start_time = time.time()  # Reset timer for display phase.\n",
    "        \n",
    "        elif phase == \"display\" and elapsed >= display_duration:\n",
    "            # Once display phase is over, reset for next measurement window.\n",
    "            phase = \"measurement\"\n",
    "            phase_start_time = time.time()\n",
    "            angle_data = {key: [] for key in angle_data}  # clear accumulator\n",
    "\n",
    "        # If in display phase, overlay the predicted label.\n",
    "        if phase == \"display\" and predicted_label is not None:\n",
    "            pred_text = f\"Prediction: {predicted_label}\"\n",
    "            cv2.putText(image, pred_text, (10, 90),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Show the resized output image.\n",
    "        cv2.imshow('MediaPipe Pose', image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "61110beffcbab1c9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tzur\\miniconda3\\envs\\pythonProject\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tzur\\miniconda3\\envs\\pythonProject\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tzur\\miniconda3\\envs\\pythonProject\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tzur\\miniconda3\\envs\\pythonProject\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 45\u001B[39m\n\u001B[32m     42\u001B[39m image.flags.writeable = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m     44\u001B[39m \u001B[38;5;66;03m# Process the image.\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m45\u001B[39m results = \u001B[43mpose\u001B[49m\u001B[43m.\u001B[49m\u001B[43mprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     47\u001B[39m \u001B[38;5;66;03m# Convert back to BGR.\u001B[39;00m\n\u001B[32m     48\u001B[39m image.flags.writeable = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\pythonProject\\Lib\\site-packages\\mediapipe\\python\\solutions\\pose.py:185\u001B[39m, in \u001B[36mPose.process\u001B[39m\u001B[34m(self, image)\u001B[39m\n\u001B[32m    164\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mprocess\u001B[39m(\u001B[38;5;28mself\u001B[39m, image: np.ndarray) -> NamedTuple:\n\u001B[32m    165\u001B[39m \u001B[38;5;250m  \u001B[39m\u001B[33;03m\"\"\"Processes an RGB image and returns the pose landmarks on the most prominent person detected.\u001B[39;00m\n\u001B[32m    166\u001B[39m \n\u001B[32m    167\u001B[39m \u001B[33;03m  Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    182\u001B[39m \u001B[33;03m         \"enable_segmentation\" is set to true.\u001B[39;00m\n\u001B[32m    183\u001B[39m \u001B[33;03m  \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m185\u001B[39m   results = \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_data\u001B[49m\u001B[43m=\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mimage\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mimage\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    186\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m results.pose_landmarks:  \u001B[38;5;66;03m# pytype: disable=attribute-error\u001B[39;00m\n\u001B[32m    187\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m landmark \u001B[38;5;129;01min\u001B[39;00m results.pose_landmarks.landmark:  \u001B[38;5;66;03m# pytype: disable=attribute-error\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\pythonProject\\Lib\\site-packages\\mediapipe\\python\\solution_base.py:340\u001B[39m, in \u001B[36mSolutionBase.process\u001B[39m\u001B[34m(self, input_data)\u001B[39m\n\u001B[32m    334\u001B[39m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    335\u001B[39m     \u001B[38;5;28mself\u001B[39m._graph.add_packet_to_input_stream(\n\u001B[32m    336\u001B[39m         stream=stream_name,\n\u001B[32m    337\u001B[39m         packet=\u001B[38;5;28mself\u001B[39m._make_packet(input_stream_type,\n\u001B[32m    338\u001B[39m                                  data).at(\u001B[38;5;28mself\u001B[39m._simulated_timestamp))\n\u001B[32m--> \u001B[39m\u001B[32m340\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_graph\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwait_until_idle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    341\u001B[39m \u001B[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001B[39;00m\n\u001B[32m    342\u001B[39m \u001B[38;5;66;03m# output stream names.\u001B[39;00m\n\u001B[32m    343\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._output_stream_type_info \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T15:36:16.551740Z",
     "start_time": "2025-04-11T15:36:16.015491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Define the mapping (if needed) for numeric labels to string labels\n",
    "label_map = {0: \"Push Ups\", 1: \"Pull Ups\", 2: \"Squats\", 3: \"Jumping Jacks\", 4: \"Planks\"}\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load the trained model.\n",
    "# -------------------------------\n",
    "with open('model_red_rf.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Load the training set to fit the scaler.\n",
    "#    The pickle file is assumed to contain a tuple: (X_train, y_train)\n",
    "# -------------------------------\n",
    "with open('trainset.pkl', 'rb') as f:\n",
    "    X_train= pickle.load(f)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Load the test set.\n",
    "#    The pickle file is assumed to contain a tuple: (X_test, y_test)\n",
    "# -------------------------------\n",
    "with open('y_testset.pkl', 'rb') as f:\n",
    "    y_test = pickle.load(f)\n",
    "    \n",
    "with open('testset.pkl', 'rb') as f:\n",
    "    X_test = pickle.load(f)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Fit the StandardScaler on the training data and transform the test set.\n",
    "# -------------------------------\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Get predictions and prediction probabilities.\n",
    "# -------------------------------\n",
    "pred = model.predict(X_test_scaled)\n",
    "pred_prob = model.predict_proba(X_test_scaled)\n",
    "\n",
    "# Optionally, map numeric predictions to string labels.\n",
    "predicted_labels = [label_map.get(p, \"Unknown\") for p in pred]\n",
    "true_labels = [label_map.get(y, \"Unknown\") for y in y_test]\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Compare predictions to true labels.\n",
    "# -------------------------------\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, pred, target_names=list(label_map.values())))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, pred))\n",
    "\n",
    "# Optionally, print a few sample predictions vs. true labels.\n",
    "print(\"\\nSample Predictions:\")\n",
    "for i in range(min(10, len(y_test))):\n",
    "    print(f\"Sample {i+1}: True Label: {true_labels[i]}, Predicted Label: {predicted_labels[i]}, Probabilities: {pred_prob[i]}\")"
   ],
   "id": "d64d7ba59cf8dd83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.97%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Push Ups       0.96      0.95      0.95       782\n",
      "     Pull Ups       0.93      0.94      0.93       999\n",
      "       Squats       0.97      0.99      0.98      1464\n",
      "Jumping Jacks       0.97      0.92      0.95       661\n",
      "       Planks       0.92      0.90      0.91       749\n",
      "\n",
      "     accuracy                           0.95      4655\n",
      "    macro avg       0.95      0.94      0.95      4655\n",
      " weighted avg       0.95      0.95      0.95      4655\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 739   30    3    3    7]\n",
      " [  13  942   17    5   22]\n",
      " [   2    2 1452    2    6]\n",
      " [   3   11   13  611   23]\n",
      " [  13   33   19    7  677]]\n",
      "\n",
      "Sample Predictions:\n",
      "Sample 1: True Label: Squats, Predicted Label: Squats, Probabilities: [0.   0.08 0.77 0.02 0.13]\n",
      "Sample 2: True Label: Squats, Predicted Label: Squats, Probabilities: [0. 0. 1. 0. 0.]\n",
      "Sample 3: True Label: Squats, Predicted Label: Squats, Probabilities: [0.   0.01 0.88 0.   0.11]\n",
      "Sample 4: True Label: Jumping Jacks, Predicted Label: Jumping Jacks, Probabilities: [0. 0. 0. 1. 0.]\n",
      "Sample 5: True Label: Push Ups, Predicted Label: Push Ups, Probabilities: [0.89 0.08 0.   0.   0.03]\n",
      "Sample 6: True Label: Planks, Predicted Label: Planks, Probabilities: [0.09 0.23 0.04 0.03 0.61]\n",
      "Sample 7: True Label: Squats, Predicted Label: Squats, Probabilities: [0. 0. 1. 0. 0.]\n",
      "Sample 8: True Label: Push Ups, Predicted Label: Push Ups, Probabilities: [1. 0. 0. 0. 0.]\n",
      "Sample 9: True Label: Push Ups, Predicted Label: Push Ups, Probabilities: [1. 0. 0. 0. 0.]\n",
      "Sample 10: True Label: Planks, Predicted Label: Planks, Probabilities: [0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "563122dfc10b1611"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
